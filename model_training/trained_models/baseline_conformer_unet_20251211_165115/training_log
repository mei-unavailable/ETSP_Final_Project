2025-12-11 16:51:15,883: Using device: cuda:0
2025-12-11 16:51:15,886: Initializing Conformer with U-Net from trained_models/unet_ssl_20251210_065837/unet_mae_epoch_50.pt
2025-12-11 16:51:16,360: Using torch.compile
2025-12-11 16:51:17,118: Initialized RNN decoding model
2025-12-11 16:51:17,118: OptimizedModule(
  (_orig_mod): UNetEnhancedModel(
    (unet): NeuralUNet(
      (inc): DoubleConv(
        (double_conv): Sequential(
          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
        )
      )
      (down1): Down(
        (maxpool_conv): Sequential(
          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (1): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
          )
        )
      )
      (down2): Down(
        (maxpool_conv): Sequential(
          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (1): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
          )
        )
      )
      (down3): Down(
        (maxpool_conv): Sequential(
          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (1): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
          )
        )
      )
      (down4): Down(
        (maxpool_conv): Sequential(
          (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (1): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (5): ReLU(inplace=True)
            )
          )
        )
      )
      (up1): Up(
        (up): Upsample(scale_factor=2.0, mode='bilinear')
        (conv): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
      (up2): Up(
        (up): Upsample(scale_factor=2.0, mode='bilinear')
        (conv): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
      (up3): Up(
        (up): Upsample(scale_factor=2.0, mode='bilinear')
        (conv): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
      (up4): Up(
        (up): Upsample(scale_factor=2.0, mode='bilinear')
        (conv): DoubleConv(
          (double_conv): Sequential(
            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): ReLU(inplace=True)
          )
        )
      )
      (outc): OutConv(
        (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (decoder): ConformerDecoder(
      (day_layer_activation): Softsign()
      (day_weights): ParameterList(
          (0): Parameter containing: [torch.float32 of size 512x512]
          (1): Parameter containing: [torch.float32 of size 512x512]
          (2): Parameter containing: [torch.float32 of size 512x512]
          (3): Parameter containing: [torch.float32 of size 512x512]
          (4): Parameter containing: [torch.float32 of size 512x512]
          (5): Parameter containing: [torch.float32 of size 512x512]
          (6): Parameter containing: [torch.float32 of size 512x512]
          (7): Parameter containing: [torch.float32 of size 512x512]
          (8): Parameter containing: [torch.float32 of size 512x512]
          (9): Parameter containing: [torch.float32 of size 512x512]
          (10): Parameter containing: [torch.float32 of size 512x512]
          (11): Parameter containing: [torch.float32 of size 512x512]
          (12): Parameter containing: [torch.float32 of size 512x512]
          (13): Parameter containing: [torch.float32 of size 512x512]
          (14): Parameter containing: [torch.float32 of size 512x512]
          (15): Parameter containing: [torch.float32 of size 512x512]
          (16): Parameter containing: [torch.float32 of size 512x512]
          (17): Parameter containing: [torch.float32 of size 512x512]
          (18): Parameter containing: [torch.float32 of size 512x512]
          (19): Parameter containing: [torch.float32 of size 512x512]
          (20): Parameter containing: [torch.float32 of size 512x512]
          (21): Parameter containing: [torch.float32 of size 512x512]
          (22): Parameter containing: [torch.float32 of size 512x512]
          (23): Parameter containing: [torch.float32 of size 512x512]
          (24): Parameter containing: [torch.float32 of size 512x512]
          (25): Parameter containing: [torch.float32 of size 512x512]
          (26): Parameter containing: [torch.float32 of size 512x512]
          (27): Parameter containing: [torch.float32 of size 512x512]
          (28): Parameter containing: [torch.float32 of size 512x512]
          (29): Parameter containing: [torch.float32 of size 512x512]
          (30): Parameter containing: [torch.float32 of size 512x512]
          (31): Parameter containing: [torch.float32 of size 512x512]
          (32): Parameter containing: [torch.float32 of size 512x512]
          (33): Parameter containing: [torch.float32 of size 512x512]
          (34): Parameter containing: [torch.float32 of size 512x512]
          (35): Parameter containing: [torch.float32 of size 512x512]
          (36): Parameter containing: [torch.float32 of size 512x512]
          (37): Parameter containing: [torch.float32 of size 512x512]
          (38): Parameter containing: [torch.float32 of size 512x512]
          (39): Parameter containing: [torch.float32 of size 512x512]
          (40): Parameter containing: [torch.float32 of size 512x512]
          (41): Parameter containing: [torch.float32 of size 512x512]
          (42): Parameter containing: [torch.float32 of size 512x512]
          (43): Parameter containing: [torch.float32 of size 512x512]
          (44): Parameter containing: [torch.float32 of size 512x512]
      )
      (day_biases): ParameterList(
          (0): Parameter containing: [torch.float32 of size 1x512]
          (1): Parameter containing: [torch.float32 of size 1x512]
          (2): Parameter containing: [torch.float32 of size 1x512]
          (3): Parameter containing: [torch.float32 of size 1x512]
          (4): Parameter containing: [torch.float32 of size 1x512]
          (5): Parameter containing: [torch.float32 of size 1x512]
          (6): Parameter containing: [torch.float32 of size 1x512]
          (7): Parameter containing: [torch.float32 of size 1x512]
          (8): Parameter containing: [torch.float32 of size 1x512]
          (9): Parameter containing: [torch.float32 of size 1x512]
          (10): Parameter containing: [torch.float32 of size 1x512]
          (11): Parameter containing: [torch.float32 of size 1x512]
          (12): Parameter containing: [torch.float32 of size 1x512]
          (13): Parameter containing: [torch.float32 of size 1x512]
          (14): Parameter containing: [torch.float32 of size 1x512]
          (15): Parameter containing: [torch.float32 of size 1x512]
          (16): Parameter containing: [torch.float32 of size 1x512]
          (17): Parameter containing: [torch.float32 of size 1x512]
          (18): Parameter containing: [torch.float32 of size 1x512]
          (19): Parameter containing: [torch.float32 of size 1x512]
          (20): Parameter containing: [torch.float32 of size 1x512]
          (21): Parameter containing: [torch.float32 of size 1x512]
          (22): Parameter containing: [torch.float32 of size 1x512]
          (23): Parameter containing: [torch.float32 of size 1x512]
          (24): Parameter containing: [torch.float32 of size 1x512]
          (25): Parameter containing: [torch.float32 of size 1x512]
          (26): Parameter containing: [torch.float32 of size 1x512]
          (27): Parameter containing: [torch.float32 of size 1x512]
          (28): Parameter containing: [torch.float32 of size 1x512]
          (29): Parameter containing: [torch.float32 of size 1x512]
          (30): Parameter containing: [torch.float32 of size 1x512]
          (31): Parameter containing: [torch.float32 of size 1x512]
          (32): Parameter containing: [torch.float32 of size 1x512]
          (33): Parameter containing: [torch.float32 of size 1x512]
          (34): Parameter containing: [torch.float32 of size 1x512]
          (35): Parameter containing: [torch.float32 of size 1x512]
          (36): Parameter containing: [torch.float32 of size 1x512]
          (37): Parameter containing: [torch.float32 of size 1x512]
          (38): Parameter containing: [torch.float32 of size 1x512]
          (39): Parameter containing: [torch.float32 of size 1x512]
          (40): Parameter containing: [torch.float32 of size 1x512]
          (41): Parameter containing: [torch.float32 of size 1x512]
          (42): Parameter containing: [torch.float32 of size 1x512]
          (43): Parameter containing: [torch.float32 of size 1x512]
          (44): Parameter containing: [torch.float32 of size 1x512]
      )
      (day_layer_dropout): Dropout(p=0.4, inplace=False)
      (projection): Linear(in_features=7168, out_features=512, bias=True)
      (conformer): Conformer(
        (conformer_layers): ModuleList(
          (0-5): 6 x ConformerLayer(
            (ffn1): _FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=512, out_features=2048, bias=True)
                (2): SiLU()
                (3): Dropout(p=0.4, inplace=False)
                (4): Linear(in_features=2048, out_features=512, bias=True)
                (5): Dropout(p=0.4, inplace=False)
              )
            )
            (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (self_attn_dropout): Dropout(p=0.4, inplace=False)
            (conv_module): _ConvolutionModule(
              (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (sequential): Sequential(
                (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))
                (1): GLU(dim=1)
                (2): Conv1d(512, 512, kernel_size=(31,), stride=(1,), padding=(15,), groups=512)
                (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (4): SiLU()
                (5): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
                (6): Dropout(p=0.4, inplace=False)
              )
            )
            (ffn2): _FeedForwardModule(
              (sequential): Sequential(
                (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
                (1): Linear(in_features=512, out_features=2048, bias=True)
                (2): SiLU()
                (3): Dropout(p=0.4, inplace=False)
                (4): Linear(in_features=2048, out_features=512, bias=True)
                (5): Dropout(p=0.4, inplace=False)
              )
            )
            (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (out): Linear(in_features=512, out_features=41, bias=True)
    )
  )
)
2025-12-11 16:51:17,122: Model has 69,136,170 parameters
2025-12-11 16:51:17,122: Model has 11,819,520 day-specific parameters | 17.10% of total parameters
2025-12-11 16:51:25,986: Successfully initialized datasets
